{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d03b9bd",
   "metadata": {},
   "source": [
    "# Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19892ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# --- 설정값 ---\n",
    "TOTAL_STEPS = 20000\n",
    "ENV_ID = 'LunarLander-v3'\n",
    "\n",
    "print(f\"'{ENV_ID}' 환경에서 총 {TOTAL_STEPS} 스텝의 데이터를 수집합니다.\")\n",
    "\n",
    "# --- 환경 초기화 ---\n",
    "env = gym.make(ENV_ID, render_mode='rgb_array')\n",
    "\n",
    "# --- 데이터 버퍼 ---\n",
    "obs_buffer = []\n",
    "frame_buffer = []\n",
    "action_buffer = []\n",
    "reward_buffer = []\n",
    "terminated_buffer = []\n",
    "truncated_buffer = []\n",
    "\n",
    "observation, info = env.reset()\n",
    "\n",
    "for _ in tqdm(range(TOTAL_STEPS)):\n",
    "    action = env.action_space.sample()\n",
    "    next_observation, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    # 버퍼에 저장\n",
    "    obs_buffer.append(observation)  # 상태 (벡터)\n",
    "    frame = env.render()            # 프레임 이미지\n",
    "    frame_buffer.append(frame)     # 이미지 추가\n",
    "\n",
    "    action_buffer.append(action)\n",
    "    reward_buffer.append(reward)\n",
    "    terminated_buffer.append(terminated)\n",
    "    truncated_buffer.append(truncated)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "    else:\n",
    "        observation = next_observation\n",
    "\n",
    "env.close()\n",
    "\n",
    "print(f\"\\n데이터 수집 완료! 총 {len(obs_buffer)}개의 경험을 저장했습니다.\")\n",
    "\n",
    "# --- 저장 디렉토리 만들기 ---\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# --- 저장 ---\n",
    "np.savez_compressed(\n",
    "    f\"data/{ENV_ID}_with_frames.npz\",\n",
    "    observations=np.array(obs_buffer, dtype=np.float32),  # (100000, 8)\n",
    "    frames=np.array(frame_buffer, dtype=np.uint8),        # (100000, H, W, 3)\n",
    "    actions=np.array(action_buffer, dtype=np.int8),\n",
    "    rewards=np.array(reward_buffer, dtype=np.float32),\n",
    "    terminateds=np.array(terminated_buffer, dtype=np.bool_),\n",
    "    truncateds=np.array(truncated_buffer, dtype=np.bool_)\n",
    ")\n",
    "\n",
    "print(f\"✅ '{ENV_ID}_with_frames.npz' 파일로 프레임 포함 데이터 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb7c4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/LunarLander-v3.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d029a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('data/LunarLander-v3.npz')\n",
    "observations_raw = data['frames']\n",
    "actions = data['actions']\n",
    "rewards = data['rewards']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985f6e3",
   "metadata": {},
   "source": [
    "# VAE train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af45596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from parts.VAE_CNN import VAE, vae_loss_function, CustomImageDataset\n",
    "from parts.MDN_RNN import MDN_RNN, mdn_rnn_loss\n",
    "from parts.controller import controller\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "observations = torch.tensor(observations_raw).permute(0, 3, 1, 2)\n",
    "vae = VAE(input_channel=3, latent_dim=512).to('cuda:0')\n",
    "\n",
    "resize = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()]) \n",
    "\n",
    "observations = CustomImageDataset(data=observations, transform=resize)\n",
    "\n",
    "dataloader = DataLoader(dataset=observations, batch_size=512)\n",
    "\n",
    "optimizer = optim.AdamW(vae.parameters(), lr=1e-4)\n",
    "\n",
    "def vae_train(vae, optimizer, dataloader, epochs=10):\n",
    "    vae.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, data in enumerate(tqdm(dataloader)):\n",
    "            data = data.to('cuda:0')\n",
    "            _, recon_image, mu, logvar = vae(data)\n",
    "\n",
    "            loss = vae_loss_function(recon_image, data, mu, logvar, beta=0.01)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(vae.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch}, Everage loss: {total_loss/len(dataloader):.6f}')\n",
    "\n",
    "vae_train(vae, optimizer, dataloader, epochs=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e6442fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/ooooAKKKKACiiigAooooAKKKKACt/VfDa6bpFneLeRyPMm9kzjjgjb69awKmubmW6l3yMTgBQM8KB2FaQlBRfMrvoBDRRRWYBRRRQAUUUUAFLgjqDz0pKuXV1d3MNvDLJI8MMYWJT0UdeKTvfQCoAScAEn2pKu6YbyHUInsllFyM+V5aktuwQMe9er6N+z/AOINY0OXUdRvo7HUJfnhtpVLE/8AXQj7pP4+9Gt/IDxuivRNO+CfjS9119Nm08WkcZ+e7lYeVj1Uj730H44qx8Qvg5qngq1TULWZtR03aBNKqbWibvuHPy+h/OmBy/iXwF4k8J3Hl6rpkqRk4SeMb43+jD+R5qbQ/hx4u8QugsdDuhG3/LaZPKjA9dzY/SvtRlVxhlBHoRS0AeH+C/2fLSwmS88U3KXsi4K2kGRGD/tN1b6cV7NDplhbwpDDZW8caAKqLEAAB2HFWqKAIVtLZGDLbxKw6EIARU1FFABTZI0mjaOVFeNxhlYZBHoRTqKAP//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAD2ElEQVR4Ae1Z30tacRS/V6/edKlliihSSLh0DdFANkGph0EwKN8GDmrBfJKCHoOg/oEFEUTroV566KWn/gAbLB+CBetBGLr2gwzBNkXJ32k7zOH8ee903+tyfC8i33vPued8zuec8/2ejCDwhRnADGAGMAOYAczAf88ALRRSfH4Xh0mSZBejx9AxA5gBzEDHGCBJPsUXdswdOOIhdCagRBbjs0emlzwehdAssyk0nngk2StW2MyesfvPM7n4p9Dbq2jgppBj9o1EiiYDfUKhfeSp1fCCFkikYs1jk9vywEVRNBKIzEbQBBDLZj9EzgvFPDiDqeFej1JEy7SqMWbfSKRoSuiWIKKJr9fpCLTBl7DvzbtX3+OfSRINO8xxogkAfEAPfEsEP4a8vvevE9dhZq//UtoDpU01CPuh3jmiewIZ6DC4BlCYEeQLBSiY+gs2n3w+mb9J14u640kPLYVPd2DFKDEDmAHMwN1noJeiOvNDClfjCgzYMNbdfaIxQswASgb6+giVimg0qlZ5AR25nED1Uy/KJnY4iI0NYmGBUKurEFfeQGO7XMT6OjEzQ0gklZI21y2P0wx+rq5EBwfZs7NiNMqgRZyfiwOBlN9PpO/a6K1SqSi2AoK/mDUaDVN8LcpQllCLrn+pC4XCiYkJq9UqEAiaWeDxeHq93uPx6HS6ZjoInreRAYVCsbq6GolELi8v19bWDAYDv667lUrl/Py83+/P5XJer9dkMnH175KWAgBSLRbL4eFhNpu9/XkVCoVAILC0tKTVaksQxWLx9PQ0gM5kMiWdYrF4enrqcDjgdQSU15j48wAA2ezsLMAFQCVk5e98Pg8Q3W73+Pj43t5ePB4vi8qLYDDodDpL/YZyXAHmUqkUEFkTWOUtUGs0Gl0u19zcnKT5PgppSafTMpmsWbWEw+Hl5eX9/X00AQAZ0IWLi4tDQ0PAUyXimjUAGhgYgF6sr/UaTdbbWCy2ubnJqsaiAIBgW1xZWQmFQvX1UE46RwtoaxZ8zGKRSARNdnx8DIXLEURWs8wIm0qhAKCUt7a2II+sPjhVIOH4AP6aIq0WQMFIpVKz2Tw1NQXcDw8Pc7KdVTtludve3oaDEPY1Zj2apkdHR6FNj46OgPXOl3uzNJIABQABrJ2dHZ/Pl0gkypFAncBGNjg4CJRPTk7a7Xa1Wv33u0fZPpIFCZGVDAF0aMfd3d2TkxM44eHEttlscFjClieXy1mnNCRo2jDyO4DSy8lk8uLiAhD39/czTFdteOLoldoAOHLDnVkORiLuwDayjANoxEonn+EMdJLtRr66PgM/AHu5LTbIMYi/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil = transforms.ToPILImage()\n",
    "to_pil(observations[15522])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc17b947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/ooooAKKKKACiiigAooooAKKKKAHKNzYq9NYbLQTLk8ZPtVAHBqwbpzD5eeKqNuoFaiiipAKKKKACiiigApcEdRSVZnubm4hhikkd4oV2xqeijrxSd+gFYAk4AyaKt6dNdWt9HPZtIlwgJRkHIOD0rtNH+EHjPxBAbwWBgEhyDdNsZj64PNGt/IDgKK9YH7P3i4xg77MOeqmXgfjisLWvhD4u0NlM1h50Z/5aQHeBTAo+LPh7rnhafdcWkj2zH5JUGR+PpVHRPBXiHxBcxw2Gl3D7zw7IVQfUnivtqS2hnjCSxq6+jDIp0cUcQxGiqPQDFAHiPgr9n61sZkvfFEyXjrgraRE7M/7R7/SvZ4dLsLeFIYbK2jiQBVRIlAUDsBirdFAEK2dsjBkt4lI7hAKlxS0UAJTXRZEKsAQR0NPpDQB/9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.eval()\n",
    "data = observations[15522].unsqueeze(0).to(\"cuda:0\")\n",
    "hidden_state, recon_image, _, _ = vae(data)\n",
    "to_pil(recon_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1381b7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae.state_dict(), 'model_weights/vae_weights_latent512.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d602a484",
   "metadata": {},
   "source": [
    "# MDN_RNN train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd6cd3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('data/LunarLander-v3.npz')\n",
    "observations_raw = data['frames']\n",
    "actions = data['actions']\n",
    "rewards = data['rewards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "# observations = torch.tensor(observations_raw).permute(0, 3, 1, 2)\n",
    "observations = observations_raw # numpy array dimension order is [H, W, C] for ToPILImage()\n",
    "\n",
    "resize = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()]) \n",
    "\n",
    "import torch\n",
    "from parts.VAE_CNN import VAE\n",
    "vae = VAE(input_channel=3, latent_dim=1024).to('cuda:0')\n",
    "vae.load_state_dict(torch.load('model_weights/vae_weights_latent1024.pth'))\n",
    "vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from parts.MDN_RNN import MDN_RNN, mdn_rnn_loss, SequenceDataset\n",
    "import numpy as np\n",
    "\n",
    "action_size = int(actions.max()) + 1\n",
    "action_onehot = np.eye(action_size)[actions] # np.eye is generates identity matrix\n",
    "\n",
    "mdn_rnn = MDN_RNN(input_size=1024, hidden_size=512, latent_space_size=1024, action_size=action_size).to('cuda:0')\n",
    "\n",
    "seq_dataset = SequenceDataset(image_dataset=observations, transforms=resize, reward_dataset=rewards, action_dataset=action_onehot, sequence_length=1000)\n",
    "dataloader = DataLoader(dataset=seq_dataset, batch_size=16, num_workers=12)\n",
    "\n",
    "optimizer = optim.AdamW(mdn_rnn.parameters(), lr=1e-4)\n",
    "\n",
    "def rnn_train(model=mdn_rnn, dataloader=dataloader, optimizer=optimizer, epochs=10):\n",
    "    model.train()\n",
    "    vae.eval()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (image, action, reward) in enumerate(tqdm(dataloader, desc=f'epoch: {epoch+1}')):\n",
    "            image, action, reward = image.to('cuda:0'), action.to('cuda:0'), reward.to('cuda:0')\n",
    "            with torch.no_grad():\n",
    "                # have to reshape image vector because vae(cnn) input shape is (batch_size, channel_size, height, width)\n",
    "                batch, sequence, C, H, W = image.size()\n",
    "                reshape_images = image.view(-1, C, H, W)\n",
    "                z_vectors_flatten, _, _, _ = vae(reshape_images)\n",
    "                z_vectors = z_vectors_flatten.view(batch, sequence, -1)\n",
    "                \n",
    "            mu, sigma, phi, p_reward, _, (_, _) = model(z_vectors, action)\n",
    "\n",
    "            batch, sequence, num_dist, latent_size = mu.size()\n",
    "\n",
    "            mu_pred = mu[: , :-1, :, :].reshape(-1, num_dist, latent_size)\n",
    "            sigma_pred = sigma[: , :-1, :, :].reshape(-1, num_dist, latent_size)\n",
    "            phi_pred = phi[: , :-1, :].reshape(-1, num_dist)\n",
    "            p_reward_pred = p_reward[:, :-1].reshape(-1, 1)\n",
    "\n",
    "            target_z =  z_vectors[: , 1:, :].reshape(-1, latent_size)\n",
    "            target_reward = reward[:, 1:].reshape(-1, 1)\n",
    "            \n",
    "            loss = mdn_rnn_loss(mu_pred, sigma_pred, phi_pred, target_z, p_reward_pred, target_reward)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(f\"loss {total_loss / (batch_idx + 1)}\")\n",
    "\n",
    "        print(f\"epoch: {epoch+1}, Everage loss: {total_loss/len(dataloader):.6f}\")\n",
    "\n",
    "rnn_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f70decd",
   "metadata": {},
   "source": [
    "# RNN test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc01a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('data/LunarLander-v3.npz')\n",
    "observations_raw = data['frames']\n",
    "actions = data['actions']\n",
    "rewards = data['rewards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc3e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from parts.VAE_CNN import VAE, vae_loss_function, CustomImageDataset\n",
    "from parts.MDN_RNN import MDN_RNN, mdn_rnn_loss, sampling, SequenceDataset\n",
    "from parts.controller import controller\n",
    "\n",
    "action_size = int(actions.max()) + 1\n",
    "action_onehot = np.eye(action_size)[actions] # np.eye is generates identity matrix\n",
    "\n",
    "vae = VAE(input_channel=3, latent_dim=256).to('cuda:0')\n",
    "mdn_rnn = MDN_RNN(input_size=256, action_size=action_size).to('cuda:0')\n",
    "controller = controller(action_size=action_size, h_vector_size=256, z_vector_size=256, hidden_size=256)\n",
    "\n",
    "vae.load_state_dict(torch.load('model_weights/vae_weights.pth'))\n",
    "mdn_rnn.load_state_dict(torch.load('model_weights/mdnrnn_weights.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9db214c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "observations = torch.tensor(observations_raw).permute(0, 3, 1, 2)\n",
    "\n",
    "resize = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()]) \n",
    "\n",
    "\n",
    "seq_dataset = SequenceDataset(image_dataset=observations, transforms=resize, action_dataset=action_onehot, reward_dataset=rewards, sequence_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec62d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "mdn_rnn.eval()\n",
    "z_vectors, _, _, _  = vae(seq_dataset[0][0].to('cuda:0'))\n",
    "z_vectors = z_vectors.unsqueeze(0)\n",
    "action_first = seq_dataset[0][1].to('cuda:0')\n",
    "action_first = action_first.unsqueeze(0)\n",
    "\n",
    "mu, sigma, phi, reward, h = mdn_rnn(z_vectors, action_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd559760",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = phi[:, -1, :]\n",
    "m = mu[:, -1, :, :]\n",
    "s = sigma[:, -1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9de9795f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDxC91S8luZibiYBmOR5je/+JqBtRvWLbrqc7vvZlbnr7/7R/M+pqCT/WNwRyeD1plQoR7Eezj2Ln9p3pLE3UxLdcyNz19/c/mfU1MNVvDkm5mJbr+8bnr7+/8AnJzm1KtPkj2E6cexdk1S9bObmbnr+8bnr7+/+c8wvqV6+7N1Od3X943PX39z+fvUDVGaOSPYFTj2LLajetu3XU53dcytz19/9o/mfU1PbareC7RmuJWy3O52OeT155+8fzPqc51Ph4mT/eFNQjfYHThbYSQbZGGCME8Gm1LcLtncbSMMeD161FQtjQKeDTKdmmJjjTDS5pKAEp8QzMg/2hTKmthm5iH+0P501uD2Jr62eO6kXYwwx4I56mqpRh2NegX/AIad5XkWI4yecf8A1qyZ/Dk43EQvwf7p/wAKfKU0zldp9KNprfbQLobj5L8dflP+FRnQ7zBP2eQY/wBg/wCH0/OlYVn2MTBo2H0NbaaFdknMEgx1+U/4fT86sJ4funHMDjHqp/wo5WFn2OcCMexq7p9tI95ENrffHQe4rfh8NzsxzEw5/un/AAra07w88UyO8bDBB6fT2qlEmSdj3DSfDUNxbRyOh5VScn2Fao8H2bbSYhxW3okkTabBtcN+7UZznPA9zWqCPUVLLOctvCenwhcwLwKuDw7p/H+ix8e1bHFFIRkf8I9p4xi2jGOOFqGXwzYOBi3QY7AVu0UActJ4UswBiJRgYwBXPa74fW2tS6IAVDdPYN/hXpJx3rJ18RHSrjdtz5b4z/utTQmf/9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import distributions\n",
    "from torchvision import transforms\n",
    "\n",
    "mixture_distribution = distributions.Categorical(probs=p)\n",
    "component_distribution = distributions.Normal(loc=m, scale=s)\n",
    "component_dist = distributions.Independent(\n",
    "    component_distribution,\n",
    "    reinterpreted_batch_ndims=1\n",
    ")\n",
    "mixture_gaussian = distributions.MixtureSameFamily(mixture_distribution, component_dist)\n",
    "vector = mixture_gaussian.sample()\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "a = vae.decode(vector)\n",
    "to_pil(a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c0e77",
   "metadata": {},
   "source": [
    "# Controller train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "676540e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from parts.MDN_RNN import MDN_RNN, sampling\n",
    "from parts.controller import controller, choice_control\n",
    "from parts.VAE_CNN import VAE\n",
    "import torch\n",
    "\n",
    "data = np.load('data/LunarLander-v3.npz')\n",
    "\n",
    "actions = data['actions']\n",
    "action_size = int(actions.max()) + 1\n",
    "\n",
    "images = data['frames']\n",
    "\n",
    "mdn_rnn = MDN_RNN(input_size=256, action_size=action_size).to('cuda:0')\n",
    "mdn_rnn.load_state_dict(torch.load('model_weights/mdnrnn_weights.pth'))\n",
    "\n",
    "vae = VAE(input_channel=3, latent_dim=256).to('cuda:0')\n",
    "vae.load_state_dict(torch.load('model_weights/vae_weights.pth'))\n",
    "vae.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "257e0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision import transforms\n",
    "import random\n",
    "\n",
    "resize = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "def sellect_random_scene(images) :\n",
    "    _len = len(images)\n",
    "    scene_number = random.randint(0, _len-1)\n",
    "    image = images[scene_number]\n",
    "    \n",
    "    image_tensor = torch.tensor(image).permute(2, 0, 1)\n",
    "\n",
    "    resized_image = torch.tensor(resize(image_tensor)).unsqueeze(0).to('cuda:0')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z_vector, _ ,_ ,_ = vae(resized_image)\n",
    "\n",
    "    num_layers, hidden_size = mdn_rnn.lstm.num_layers, mdn_rnn.lstm.hidden_size\n",
    "\n",
    "    h_vector = torch.zeros(1, hidden_size).to('cuda:0')\n",
    "\n",
    "    h_n, c_n = torch.zeros(num_layers, 1, hidden_size).to('cuda:0'), torch.zeros(num_layers, 1, hidden_size).to('cuda:0')\n",
    "\n",
    "    return z_vector, h_vector, (h_n, c_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8658277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parts.MDN_RNN import MDN_RNN, sampling\n",
    "from parts.controller import controller, choice_control\n",
    "import torch\n",
    "\n",
    "C = controller(action_size=action_size, z_vector_size=256, h_vector_size=256, hidden_size=256).to('cuda:0')\n",
    "\n",
    "optimizer = torch.optim.AdamW(C.parameters(), lr=1e-4)\n",
    "\n",
    "def controller_train(steps, controller, optimizer, initial_z, initial_h, cell):\n",
    "    controller.train()\n",
    "    mdn_rnn.train()\n",
    "\n",
    "    rewards = []\n",
    "    z = initial_z.to('cuda:0')\n",
    "    h = initial_h.to('cuda:0')\n",
    "\n",
    "    z_rnn = z.unsqueeze(0)\n",
    "\n",
    "    for _ in range(steps):\n",
    "        action_prob = controller(z, h)\n",
    "        action = choice_control(action_prob)\n",
    "        action_onehot = np.eye(action_size)[action]\n",
    "        action_onehot_tensor = torch.tensor(action_onehot).unsqueeze(0).unsqueeze(0).to(torch.float32).to('cuda:0')\n",
    "\n",
    "        mu, sigma, phi, reward, h, cell = mdn_rnn(z_rnn, action_onehot_tensor, cell)\n",
    "\n",
    "        z_rnn = sampling(mu, sigma, phi) \n",
    "        z = z_rnn.squeeze(0)\n",
    "\n",
    "        rewards.append(reward)\n",
    "\n",
    "\n",
    "    total_imagined_reward = torch.stack(rewards).sum()\n",
    "    loss = -total_imagined_reward\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5087c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for _ in tqdm(range(10000)):\n",
    "    initial_z, initial_h, (h_n, c_n) = sellect_random_scene(images)\n",
    "    loss = controller_train(1000, C, optimizer, initial_z, initial_h, (h_n, c_n))\n",
    "    print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "world-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
